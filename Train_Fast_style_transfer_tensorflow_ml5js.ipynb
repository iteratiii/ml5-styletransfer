{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfPL3z-gDHuQ"
      },
      "source": [
        "# Train and Style Transfer model and run it in ml5.js/tf.js"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcY9cMXsDL8b"
      },
      "source": [
        "## 1. Preparing your environment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Dkk2v3JCuEW",
        "outputId": "498ff39a-f511-43b7-eed7-343a4261af3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'fast-style-transfer'...\n",
            "remote: Enumerating objects: 248, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 248 (delta 2), reused 5 (delta 0), pack-reused 238\u001b[K\n",
            "Receiving objects: 100% (248/248), 11.02 MiB | 26.37 MiB/s, done.\n",
            "Resolving deltas: 100% (113/113), done.\n"
          ]
        }
      ],
      "source": [
        "# Clone the fast-style-transfer git repo from github: https://github.com/lengstrom/fast-style-transfer.\n",
        "!git clone https://github.com/lengstrom/fast-style-transfer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4qwxD7ZEMgD"
      },
      "source": [
        "### Add a style image\n",
        "1. Go to left sidebar, click on the folder icon to open \"Files\" panel\n",
        "2. Create a folder called 'ckpt' inside of 'fast-style-transfer' folder\n",
        "3. Create another folder called 'images' inside of 'fast-style-transfer' folder\n",
        "4. Inside of the 'images' folder, create a folder called 'style'\n",
        "5. Put a style image inside of the 'style' folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cF1kfOS9dJHF"
      },
      "source": [
        "### Install some libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jii5lBIVY1cs",
        "outputId": "ff5dba27-65ae-439a-b326-f8a2752866d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.1.0\n",
            "  Downloading tensorflow_gpu-2.1.0-cp37-cp37m-manylinux2010_x86_64.whl (421.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8 MB 4.7 kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0) (1.12.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0) (0.12.0)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "  Downloading tensorboard-2.1.1-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 21.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0) (0.8.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0) (1.15.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0) (1.19.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0) (3.3.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0) (1.41.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0) (3.17.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0) (0.37.0)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "  Downloading tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 42.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.1.0) (3.1.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (57.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (3.3.4)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (2021.5.30)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (3.1.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow-gpu==2.1.0) (1.5.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (3.7.4.3)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=ee2d3e8ca5670dd18e00014950c84e45d41d5f83508df9449080695ed0bf2a74\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow-gpu\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.6.0\n",
            "    Uninstalling tensorflow-estimator-2.6.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.6.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.6.0\n",
            "    Uninstalling tensorboard-2.6.0:\n",
            "      Successfully uninstalled tensorboard-2.6.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.6.0 requires gast==0.4.0, but you have gast 0.2.2 which is incompatible.\n",
            "tensorflow 2.6.0 requires tensorboard~=2.6, but you have tensorboard 2.1.1 which is incompatible.\n",
            "tensorflow 2.6.0 requires tensorflow-estimator~=2.6, but you have tensorflow-estimator 2.1.0 which is incompatible.\n",
            "tensorflow-probability 0.14.1 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-2.1.1 tensorflow-estimator-2.1.0 tensorflow-gpu-2.1.0\n"
          ]
        }
      ],
      "source": [
        "# Install tensorflow\n",
        "!pip install tensorflow-gpu==2.1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEctG-61ZIF6",
        "outputId": "d6322617-0794-43b7-8114-7a034c18b44a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.7/dist-packages (0.2.3.5)\n",
            "Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.7/dist-packages (from moviepy) (2.4.1)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.7/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.7/dist-packages (from moviepy) (4.62.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from moviepy) (1.19.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio<3.0,>=2.1.2->moviepy) (7.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy) (1.19.5)\n"
          ]
        }
      ],
      "source": [
        "# Install other libraries\n",
        "!apt install ffmpeg\n",
        "!pip install moviepy\n",
        "!pip install scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-DB6canDn5B",
        "outputId": "70de73a7-7662-46d3-d0ea-7a64f0a524dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/fast-style-transfer\n"
          ]
        }
      ],
      "source": [
        "# go to fast-style-transfer \n",
        "%cd fast-style-transfer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0cGgkydQV6n",
        "outputId": "68369083-18bc-4429-cb3d-3636bbce75c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CITATION.cff  docs.md      \u001b[0m\u001b[01;34mexamples\u001b[0m/  README.md  \u001b[01;34msrc\u001b[0m/      transform_video.py\n",
            "\u001b[01;34mckpt\u001b[0m/         evaluate.py  \u001b[01;34mimages\u001b[0m/    \u001b[01;32msetup.sh\u001b[0m*  style.py\n"
          ]
        }
      ],
      "source": [
        "%ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSC4tPjEImCI"
      },
      "source": [
        "# 2. Downloading Datasets\n",
        "\n",
        "The following step is downloading dataset, it may take 1 hour to finish. Keep this web tab active, and don't close it, wait util the following cell stopped loading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8shkSNWddtvm",
        "outputId": "ca8fdd5e-8d54-4e15-9db5-35ebd5505bdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-10-09 00:35:53--  http://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat\n",
            "Resolving www.vlfeat.org (www.vlfeat.org)... 64.90.48.57\n",
            "Connecting to www.vlfeat.org (www.vlfeat.org)|64.90.48.57|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat [following]\n",
            "--2021-10-09 00:35:53--  https://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat\n",
            "Connecting to www.vlfeat.org (www.vlfeat.org)|64.90.48.57|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 576042600 (549M)\n",
            "Saving to: ‘imagenet-vgg-verydeep-19.mat’\n",
            "\n",
            "imagenet-vgg-veryde 100%[===================>] 549.36M  33.1MB/s    in 19s     \n",
            "\n",
            "2021-10-09 00:36:13 (29.0 MB/s) - ‘imagenet-vgg-verydeep-19.mat’ saved [576042600/576042600]\n",
            "\n",
            "--2021-10-09 00:36:13--  http://msvocds.blob.core.windows.net/coco2014/train2014.zip\n",
            "Resolving msvocds.blob.core.windows.net (msvocds.blob.core.windows.net)... 20.60.195.163\n",
            "Connecting to msvocds.blob.core.windows.net (msvocds.blob.core.windows.net)|20.60.195.163|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13510573713 (13G) [application/octet-stream]\n",
            "Saving to: ‘train2014.zip’\n",
            "\n",
            "train2014.zip       100%[===================>]  12.58G  34.2MB/s    in 5m 34s  \n",
            "\n",
            "2021-10-09 00:41:46 (38.6 MB/s) - ‘train2014.zip’ saved [13510573713/13510573713]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!./setup.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwj2HgUlIrtH"
      },
      "source": [
        "# 3. Training with style.py\n",
        "Keep this cell running, keep the tab active and wait. It took me 2 hours."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypI9UexsKiiN",
        "outputId": "1e447e95-3f9a-4b4b-e60d-923b884862b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2021-10-09 00:47:46.015196: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2021-10-09 00:47:46.015949: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2021-10-09 00:47:46.015980: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Train set has been trimmed slightly..\n",
            "(1, 1042, 1886, 3)\n",
            "2021-10-09 00:47:50.188232: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-10-09 00:47:50.241516: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-09 00:47:50.242665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2021-10-09 00:47:50.267394: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-10-09 00:47:50.495109: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-10-09 00:47:50.537130: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-10-09 00:47:50.631742: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-10-09 00:47:50.820416: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-10-09 00:47:50.838971: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-10-09 00:47:51.293363: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-10-09 00:47:51.293609: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-09 00:47:51.294546: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-09 00:47:51.295276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
            "2021-10-09 00:47:51.295883: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2021-10-09 00:47:51.305469: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
            "2021-10-09 00:47:51.305975: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56545affca00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-10-09 00:47:51.306015: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-10-09 00:47:51.455965: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-09 00:47:51.456784: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56545affcbc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-10-09 00:47:51.456843: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2021-10-09 00:47:51.458223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-09 00:47:51.459024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2021-10-09 00:47:51.459108: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-10-09 00:47:51.459160: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-10-09 00:47:51.459214: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-10-09 00:47:51.459266: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-10-09 00:47:51.459316: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-10-09 00:47:51.459361: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-10-09 00:47:51.459408: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-10-09 00:47:51.459509: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-09 00:47:51.460340: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-09 00:47:51.461000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
            "2021-10-09 00:47:51.467182: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-10-09 00:47:51.468829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-10-09 00:47:51.468867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n",
            "2021-10-09 00:47:51.468888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n",
            "2021-10-09 00:47:51.473143: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-09 00:47:51.473957: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-09 00:47:51.474862: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-10-09 00:47:51.474940: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "2021-10-09 00:48:06.032526: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 23582544 exceeds 10% of system memory.\n",
            "2021-10-09 00:48:06.170562: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 23582544 exceeds 10% of system memory.\n",
            "2021-10-09 00:48:06.225929: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 503094272 exceeds 10% of system memory.\n",
            "2021-10-09 00:48:07.451076: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 23582544 exceeds 10% of system memory.\n",
            "2021-10-09 00:48:07.482117: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 23582544 exceeds 10% of system memory.\n",
            "tcmalloc: large alloc 4528087040 bytes == 0x5654e2a08000 @  0x7ff813abf1e7 0x7ff7c3d12c55 0x7ff7c3d2b115 0x7ff7c8ae3afa 0x7ff7c90c2132 0x7ff7c90c31c1 0x7ff7c919034e 0x7ff7c9193efd 0x7ff7c91943ef 0x7ff7bfb1759c 0x7ff7bfb09b85 0x7ff7bfbf85d1 0x7ff7bfbf52e3 0x7ff8123a16df 0x7ff8138746db 0x7ff8129a971f\n",
            "tcmalloc: large alloc 4528087040 bytes == 0x5654c4a3e000 @  0x7ff813abf1e7 0x7ff7c3d12c55 0x7ff7c3d2b115 0x7ff7c8ae3afa 0x7ff7c90c2132 0x7ff7c90c31c1 0x7ff7c919034e 0x7ff7c9193efd 0x7ff7c91943ef 0x7ff7bfb1759c 0x7ff7bfb09b85 0x7ff7bfbf85d1 0x7ff7bfbf52e3 0x7ff8123a16df 0x7ff8138746db 0x7ff8129a971f\n",
            "tcmalloc: large alloc 4528087040 bytes == 0x5654e2a08000 @  0x7ff813abf1e7 0x7ff7c3d12c55 0x7ff7c3d2b115 0x7ff7c8ae3afa 0x7ff7c90c2132 0x7ff7c90c31c1 0x7ff7c919034e 0x7ff7c9193efd 0x7ff7c91943ef 0x7ff7bfb1759c 0x7ff7bfb09b85 0x7ff7bfbf85d1 0x7ff7bfbf52e3 0x7ff8123a16df 0x7ff8138746db 0x7ff8129a971f\n",
            "tcmalloc: large alloc 4528087040 bytes == 0x5654e2a08000 @  0x7ff813abf1e7 0x7ff7c3d12c55 0x7ff7c3d2b115 0x7ff7c8ae3afa 0x7ff7c90c2132 0x7ff7c90c31c1 0x7ff7c919034e 0x7ff7c9193efd 0x7ff7c91943ef 0x7ff7bfb1759c 0x7ff7bfb09b85 0x7ff7bfbf85d1 0x7ff7bfbf52e3 0x7ff8123a16df 0x7ff8138746db 0x7ff8129a971f\n",
            "2021-10-09 00:49:01.445491: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-09 00:49:01.446434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2021-10-09 00:49:01.446524: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-10-09 00:49:01.446565: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-10-09 00:49:01.446603: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-10-09 00:49:01.446639: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-10-09 00:49:01.446680: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-10-09 00:49:01.446717: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-10-09 00:49:01.446754: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-10-09 00:49:01.446865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-09 00:49:01.447673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-09 00:49:01.448430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
            "2021-10-09 00:49:01.448491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-10-09 00:49:01.448513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n",
            "2021-10-09 00:49:01.448529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n",
            "2021-10-09 00:49:01.448659: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-09 00:49:01.449497: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-09 00:49:01.450246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "UID: 11\n",
            "2021-10-09 00:49:14.201222: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-10-09 00:49:17.910249: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "Epoch 0, Iteration: 2000, Loss: 6408985.0\n",
            "style: 1894005.8, content:4322018.5, tv: 192961.16\n"
          ]
        }
      ],
      "source": [
        "# Remember to replace the name after 'images/style/' to your own style image name\n",
        "# You can change the number after --epoch to change the training time, default to 2, it has to be > 0\n",
        "!python style.py --checkpoint-dir ckpt --style images/style/plaz.png --style-weight 1.5e2 --train-path data/train2014 --vgg-path data/imagenet-vgg-verydeep-19.mat --epochs 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQX2AeuXd-LB"
      },
      "source": [
        "At this point, you will be able to see 4 files in the '/fast-style-transfer/ckpt' folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziBLDaHSIr_2"
      },
      "source": [
        "# 4. Converting model to ml5js"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "903jSW-5WlAr",
        "outputId": "8e02a36a-aef4-4891-e011-dfc27db47eb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
            "\u001b[K     |████████████████████████████████| 109.2MB 53kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.12.4)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 39.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.35.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 59.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.18.5)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.32.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (50.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.0)\n",
            "\u001b[31mERROR: tensorflow-gpu 2.1.0 has requirement tensorboard<2.2.0,>=2.1.0, but you'll have tensorboard 1.14.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-gpu 2.1.0 has requirement tensorflow-estimator<2.2.0,>=2.1.0rc0, but you'll have tensorflow-estimator 1.14.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.1.1\n",
            "    Uninstalling tensorboard-2.1.1:\n",
            "      Successfully uninstalled tensorboard-2.1.1\n",
            "  Found existing installation: tensorflow-estimator 2.1.0\n",
            "    Uninstalling tensorflow-estimator-2.1.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.1.0\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow==1.14.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "yW2jDqCOX7Un",
        "outputId": "e0cae064-e7f4-4776-fed4-73d1e8516125"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'fast-style-transfer-deeplearnjs'...\n",
            "remote: Enumerating objects: 1407, done.\u001b[K\n",
            "remote: Total 1407 (delta 0), reused 0 (delta 0), pack-reused 1407\u001b[K\n",
            "Receiving objects: 100% (1407/1407), 37.97 MiB | 1.56 MiB/s, done.\n",
            "Resolving deltas: 100% (135/135), done.\n",
            "/content/fast-style-transfer-deeplearnjs\n"
          ]
        }
      ],
      "source": [
        "%cd ../\n",
        "!git clone https://github.com/reiinakano/fast-style-transfer-deeplearnjs.git\n",
        "%cd fast-style-transfer-deeplearnjs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N6ky6qQhYJBz",
        "outputId": "60d8c1b8-4dfc-4d67-cea7-15a18695e140"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "WARNING:tensorflow:From scripts/dump_checkpoint_vars.py:48: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
            "\n",
            "WARNING:tensorflow:From scripts/dump_checkpoint_vars.py:51: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "Writing variable Variable_9/Adam_1...\n",
            "Writing variable Variable_8/Adam...\n",
            "Writing variable Variable_8...\n",
            "Writing variable Variable_7/Adam_1...\n",
            "Writing variable Variable_7/Adam...\n",
            "Writing variable Variable_7...\n",
            "Writing variable Variable_6/Adam...\n",
            "Writing variable Variable_6...\n",
            "Writing variable Variable_5/Adam...\n",
            "Writing variable Variable_47/Adam_1...\n",
            "Writing variable Variable_45/Adam_1...\n",
            "Writing variable Variable_45/Adam...\n",
            "Writing variable Variable_45...\n",
            "Writing variable Variable_43/Adam_1...\n",
            "Writing variable Variable_43/Adam...\n",
            "Writing variable Variable_43...\n",
            "Writing variable Variable_5/Adam_1...\n",
            "Writing variable Variable_42/Adam...\n",
            "Writing variable Variable_41/Adam...\n",
            "Writing variable Variable_41...\n",
            "Writing variable Variable_40...\n",
            "Writing variable Variable_39/Adam_1...\n",
            "Writing variable Variable_39...\n",
            "Writing variable Variable_38/Adam_1...\n",
            "Writing variable Variable_4/Adam_1...\n",
            "Writing variable Variable_38...\n",
            "Writing variable Variable_44...\n",
            "Writing variable Variable_20/Adam...\n",
            "Writing variable Variable_10/Adam...\n",
            "Writing variable Variable_37/Adam...\n",
            "Writing variable Variable_31/Adam...\n",
            "Writing variable Variable_19/Adam...\n",
            "Writing variable Variable_25...\n",
            "Writing variable Variable_9...\n",
            "Writing variable Variable_32/Adam...\n",
            "Writing variable Variable_34...\n",
            "Writing variable Variable_5...\n",
            "Writing variable Variable_47/Adam...\n",
            "Writing variable Variable_17/Adam_1...\n",
            "Writing variable Variable_32...\n",
            "Writing variable Variable_18/Adam...\n",
            "Writing variable Variable_17/Adam...\n",
            "Writing variable Variable_19/Adam_1...\n",
            "Writing variable Variable_11/Adam_1...\n",
            "Writing variable Variable_17...\n",
            "Writing variable Variable_18...\n",
            "Writing variable Variable_44/Adam_1...\n",
            "Writing variable Variable_36...\n",
            "Writing variable Variable_16...\n",
            "Writing variable Variable_2...\n",
            "Writing variable Variable_14/Adam_1...\n",
            "Writing variable beta2_power...\n",
            "Writing variable Variable_15...\n",
            "Writing variable Variable_30...\n",
            "Writing variable Variable_15/Adam_1...\n",
            "Writing variable Variable_46...\n",
            "Writing variable Variable_15/Adam...\n",
            "Writing variable Variable_24/Adam...\n",
            "Writing variable Variable_16/Adam...\n",
            "Writing variable Variable_11...\n",
            "Writing variable Variable_2/Adam_1...\n",
            "Writing variable Variable_41/Adam_1...\n",
            "Writing variable Variable_38/Adam...\n",
            "Writing variable Variable_23...\n",
            "Writing variable Variable_10/Adam_1...\n",
            "Writing variable Variable_24...\n",
            "Writing variable Variable_37/Adam_1...\n",
            "Writing variable Variable_47...\n",
            "Writing variable Variable_14...\n",
            "Writing variable Variable_20...\n",
            "Writing variable Variable_30/Adam...\n",
            "Writing variable Variable_1/Adam...\n",
            "Writing variable Variable_29/Adam_1...\n",
            "Writing variable Variable/Adam_1...\n",
            "Writing variable Variable_19...\n",
            "Writing variable Variable_21/Adam_1...\n",
            "Writing variable Variable_11/Adam...\n",
            "Writing variable Variable_29...\n",
            "Writing variable Variable_22...\n",
            "Writing variable Variable_16/Adam_1...\n",
            "Writing variable beta1_power...\n",
            "Writing variable Variable_40/Adam_1...\n",
            "Writing variable Variable_1...\n",
            "Writing variable Variable_44/Adam...\n",
            "Writing variable Variable_12...\n",
            "Writing variable Variable_36/Adam...\n",
            "Writing variable Variable/Adam...\n",
            "Writing variable Variable_25/Adam...\n",
            "Writing variable Variable_12/Adam_1...\n",
            "Writing variable Variable_23/Adam_1...\n",
            "Writing variable Variable_12/Adam...\n",
            "Writing variable Variable_21...\n",
            "Writing variable Variable_27...\n",
            "Writing variable Variable_4...\n",
            "Writing variable Variable_37...\n",
            "Writing variable Variable_10...\n",
            "Writing variable Variable_13...\n",
            "Writing variable Variable_28/Adam...\n",
            "Writing variable Variable_33/Adam_1...\n",
            "Writing variable Variable_13/Adam_1...\n",
            "Writing variable Variable_14/Adam...\n",
            "Writing variable Variable_3/Adam_1...\n",
            "Writing variable Variable_18/Adam_1...\n",
            "Writing variable Variable_2/Adam...\n",
            "Writing variable Variable_31/Adam_1...\n",
            "Writing variable Variable_9/Adam...\n",
            "Writing variable Variable_42/Adam_1...\n",
            "Writing variable Variable_22/Adam...\n",
            "Writing variable Variable_6/Adam_1...\n",
            "Writing variable Variable_22/Adam_1...\n",
            "Writing variable Variable_23/Adam...\n",
            "Writing variable Variable_28/Adam_1...\n",
            "Writing variable Variable_35/Adam_1...\n",
            "Writing variable Variable_20/Adam_1...\n",
            "Writing variable Variable_26/Adam...\n",
            "Writing variable Variable_40/Adam...\n",
            "Writing variable Variable_4/Adam...\n",
            "Writing variable Variable_30/Adam_1...\n",
            "Writing variable Variable_33/Adam...\n",
            "Writing variable Variable_26/Adam_1...\n",
            "Writing variable Variable_26...\n",
            "Writing variable Variable_27/Adam_1...\n",
            "Writing variable Variable_1/Adam_1...\n",
            "Writing variable Variable_29/Adam...\n",
            "Writing variable Variable_25/Adam_1...\n",
            "Writing variable Variable_28...\n",
            "Writing variable Variable_3...\n",
            "Writing variable Variable_42...\n",
            "Writing variable Variable_39/Adam...\n",
            "Writing variable Variable_3/Adam...\n",
            "Writing variable Variable_31...\n",
            "Writing variable Variable_8/Adam_1...\n",
            "Writing variable Variable_21/Adam...\n",
            "Writing variable Variable_32/Adam_1...\n",
            "Writing variable Variable_13/Adam...\n",
            "Writing variable Variable_27/Adam...\n",
            "Writing variable Variable_33...\n",
            "Writing variable Variable_34/Adam...\n",
            "Writing variable Variable_34/Adam_1...\n",
            "Writing variable Variable_46/Adam_1...\n",
            "Writing variable Variable_24/Adam_1...\n",
            "Writing variable Variable_35...\n",
            "Writing variable Variable_35/Adam...\n",
            "Writing variable Variable_46/Adam...\n",
            "Writing variable Variable...\n",
            "Writing variable Variable_36/Adam_1...\n",
            "Writing manifest to src/ckpts/pollock/manifest.json\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "# Change src/ckpts/picasso to src/ckpts/YOUR_OWN_FOLDER\n",
        "!python scripts/dump_checkpoint_vars.py --output_dir=src/ckpts/plaz --checkpoint_file=../fast-style-transfer/ckpt/fns.ckpt\n",
        "# Change src/ckpts/picasso to src/ckpts/YOUR_OWN_FOLDER\n",
        "!python scripts/remove_optimizer_variables.py --output_dir=src/ckpts/plaz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "id": "YCt42jBqY_rA",
        "outputId": "1540202d-537c-49ab-8675-b3a0ac321ae4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/ (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_47 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_25 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_43 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_13 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_28 (deflated 2%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_40 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_37 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_26 (deflated 4%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_23 (deflated 4%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_41 (deflated 1%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_11 (deflated 4%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_7 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_36 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_12 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_14 (deflated 2%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_17 (deflated 5%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_5 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_32 (deflated 5%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_42 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_10 (deflated 2%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_29 (deflated 5%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_20 (deflated 3%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_44 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_34 (deflated 2%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_1 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_33 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_9 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_45 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_22 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_6 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_18 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_16 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_46 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_15 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_4 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_21 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_19 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_38 (deflated 4%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_24 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/manifest.json (deflated 91%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_8 (deflated 1%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_35 (deflated 6%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_27 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_2 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_30 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_3 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_31 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_39 (deflated 7%)\n"
          ]
        }
      ],
      "source": [
        "# Change /piccasso.zip to /YOUR_FOLDER_NAME.zip, same as src/ckpts/picasso to /YOUR_FOLDER_NAME\n",
        "!zip -r /content/fast-style-transfer-deeplearnjs/src/ckpts/picasso.zip /content/fast-style-transfer-deeplearnjs/src/ckpts/picasso"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8_X2DJIMiJW"
      },
      "source": [
        "# 5. Run it with ml5js\n",
        "Now, you should be able to see a 'pollock' .zip file at \"fast-style-transfer-deeplearnjs/src/ckpts/pollock.zip\". (Sometimes, you need to refresh the Files panel, right click to refresh)\n",
        "\n",
        "Download the 'pollock' folder and put it into your p5 sketch(https://github.com/yining1023/machine-learning-for-the-web/tree/master/week5-styleTransfer/styleTransfer-ml5/StyleTransfer_Video) under models/.\n",
        "\n",
        "Change the model path in your p5 sketch: style = ml5.styleTransfer('models/pollock', video, modelLoaded);"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}