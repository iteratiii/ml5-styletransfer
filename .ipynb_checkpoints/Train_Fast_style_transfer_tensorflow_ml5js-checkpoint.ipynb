{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IfPL3z-gDHuQ"
   },
   "source": [
    "# Train and Style Transfer model and run it in ml5.js/tf.js"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VcY9cMXsDL8b"
   },
   "source": [
    "## 1. Preparing your environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Dkk2v3JCuEW",
    "outputId": "498ff39a-f511-43b7-eed7-343a4261af3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'fast-style-transfer'...\n",
      "remote: Enumerating objects: 248, done.\u001b[K\n",
      "remote: Total 248 (delta 0), reused 0 (delta 0), pack-reused 248\u001b[K\n",
      "Receiving objects: 100% (248/248), 11.02 MiB | 3.78 MiB/s, done.\n",
      "Resolving deltas: 100% (114/114), done.\n"
     ]
    }
   ],
   "source": [
    "# Clone the fast-style-transfer git repo from github: https://github.com/lengstrom/fast-style-transfer.\n",
    "!git clone https://github.com/lengstrom/fast-style-transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F4qwxD7ZEMgD"
   },
   "source": [
    "### Add a style image\n",
    "1. Go to left sidebar, click on the folder icon to open \"Files\" panel\n",
    "2. Create a folder called 'ckpt' inside of 'fast-style-transfer' folder\n",
    "3. Create another folder called 'images' inside of 'fast-style-transfer' folder\n",
    "4. Inside of the 'images' folder, create a folder called 'style'\n",
    "5. Put a style image inside of the 'style' folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cF1kfOS9dJHF"
   },
   "source": [
    "### Install some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jii5lBIVY1cs",
    "outputId": "ff5dba27-65ae-439a-b326-f8a2752866d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.11.0-cp39-cp39-macosx_10_14_x86_64.whl (244.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting libclang>=13.0.0\n",
      "  Downloading libclang-15.0.6.1-py2.py3-none-macosx_10_9_x86_64.whl (25.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.0/25.0 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /Users/gabriel/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.14.1)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: packaging in /Users/gabriel/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (21.3)\n",
      "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.2.0-py3-none-any.whl (6.6 kB)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.6-cp39-cp39-macosx_10_9_x86_64.whl (980 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m980.5/980.5 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-23.3.3-py2.py3-none-any.whl (26 kB)\n",
      "Collecting keras<2.12,>=2.11.0\n",
      "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /Users/gabriel/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.24.2)\n",
      "Requirement already satisfied: setuptools in /Users/gabriel/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (63.4.1)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-macosx_10_14_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /Users/gabriel/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/gabriel/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.7.0)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /Users/gabriel/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (4.3.0)\n",
      "Collecting tensorboard<2.12,>=2.11\n",
      "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.51.3-cp39-cp39-macosx_10_10_universal2.whl (8.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /Users/gabriel/opt/anaconda3/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/gabriel/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.28.1)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /Users/gabriel/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.0.3)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.16.2-py2.py3-none-any.whl (177 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.2/177.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /Users/gabriel/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.3.4)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/gabriel/opt/anaconda3/lib/python3.9/site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/gabriel/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/gabriel/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/gabriel/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/gabriel/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/gabriel/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/gabriel/opt/anaconda3/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tensorboard-plugin-wit, libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, protobuf, opt-einsum, oauthlib, keras, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.0 flatbuffers-23.3.3 gast-0.4.0 google-auth-2.16.2 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.51.3 keras-2.11.0 libclang-15.0.6.1 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-3.19.6 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.2.0\n"
     ]
    }
   ],
   "source": [
    "# Install tensorflow\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LEctG-61ZIF6",
    "outputId": "d6322617-0794-43b7-8114-7a034c18b44a"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4088168850.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/lj/gz81psj55xg1_fm6jfz2vbn80000gn/T/ipykernel_13083/4088168850.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    install ffmpeg\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Install other libraries\n",
    "!apt install ffmpeg\n",
    "!pip install moviepy\n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ffmpeg\n",
      "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: ffmpeg\n",
      "  Building wheel for ffmpeg (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6083 sha256=24fd7fef36a97a71d7f736e3539d3f0d76fe0419308cb0520898339372d1885d\n",
      "  Stored in directory: /Users/gabriel/Library/Caches/pip/wheels/1d/57/24/4eff6a03a9ea0e647568e8a5a0546cdf957e3cf005372c0245\n",
      "Successfully built ffmpeg\n",
      "Installing collected packages: ffmpeg\n",
      "Successfully installed ffmpeg-1.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x-DB6canDn5B",
    "outputId": "70de73a7-7662-46d3-d0ea-7a64f0a524dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gabriel/Documents/GitHub/ml5-styletransfer/fast-style-transfer\n"
     ]
    }
   ],
   "source": [
    "# go to fast-style-transfer \n",
    "%cd fast-style-transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q0cGgkydQV6n",
    "outputId": "68369083-18bc-4429-cb3d-3636bbce75c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CITATION.cff        evaluate.py         \u001b[34msrc\u001b[m\u001b[m/\r\n",
      "README.md           \u001b[34mexamples\u001b[m\u001b[m/           style.py\r\n",
      "docs.md             \u001b[31msetup.sh\u001b[m\u001b[m*           transform_video.py\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSC4tPjEImCI"
   },
   "source": [
    "# 2. Downloading Datasets\n",
    "\n",
    "The following step is downloading dataset, it may take 1 hour to finish. Keep this web tab active, and don't close it, wait util the following cell stopped loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8shkSNWddtvm",
    "outputId": "ca8fdd5e-8d54-4e15-9db5-35ebd5505bdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-13 00:57:24--  http://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat\n",
      "Resolving www.vlfeat.org (www.vlfeat.org)... 64.90.48.57\n",
      "Connecting to www.vlfeat.org (www.vlfeat.org)|64.90.48.57|:80... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat [following]\n",
      "--2023-03-13 00:57:24--  https://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat\n",
      "Connecting to www.vlfeat.org (www.vlfeat.org)|64.90.48.57|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 576042600 (549M)\n",
      "Saving to: 'imagenet-vgg-verydeep-19.mat'\n",
      "\n",
      "imagenet-vgg-veryde 100%[===================>] 549.36M  4.29MB/s    in 2m 17s  \n",
      "\n",
      "2023-03-13 00:59:41 (4.00 MB/s) - 'imagenet-vgg-verydeep-19.mat' saved [576042600/576042600]\n",
      "\n",
      "--2023-03-13 00:59:41--  http://msvocds.blob.core.windows.net/coco2014/train2014.zip\n",
      "Resolving msvocds.blob.core.windows.net (msvocds.blob.core.windows.net)... 20.60.195.163\n",
      "Connecting to msvocds.blob.core.windows.net (msvocds.blob.core.windows.net)|20.60.195.163|:80... connected.\n",
      "HTTP request sent, awaiting response... 409 Public access is not permitted on this storage account.\n",
      "2023-03-13 00:59:42 ERROR 409: Public access is not permitted on this storage account..\n",
      "\n",
      "unzip:  cannot find or open train2014.zip, train2014.zip.zip or train2014.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "!./setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lwj2HgUlIrtH"
   },
   "source": [
    "# 3. Training with style.py\n",
    "Keep this cell running, keep the tab active and wait. It took me 2 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "ypI9UexsKiiN",
    "outputId": "1e447e95-3f9a-4b4b-e60d-923b884862b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-13 01:37:02.194385: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n"
     ]
    }
   ],
   "source": [
    "# Remember to replace the name after 'images/style/' to your own style image name\n",
    "# You can change the number after --epoch to change the training time, default to 2, it has to be > 0\n",
    "!python style.py --checkpoint-dir ckpt --style images/style/daguerrotype.jpg --style-weight 1.5e2 --train-path data/train2014 --vgg-path data/imagenet-vgg-verydeep-19.mat --epochs 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQX2AeuXd-LB"
   },
   "source": [
    "At this point, you will be able to see 4 files in the '/fast-style-transfer/ckpt' folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ziBLDaHSIr_2"
   },
   "source": [
    "# 4. Converting model to ml5js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 734
    },
    "id": "903jSW-5WlAr",
    "outputId": "8e02a36a-aef4-4891-e011-dfc27db47eb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==1.14.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
      "\u001b[K     |████████████████████████████████| 109.2MB 53kB/s \n",
      "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.10.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.12.4)\n",
      "Collecting tensorboard<1.15.0,>=1.14.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2MB 39.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.35.1)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
      "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
      "\u001b[K     |████████████████████████████████| 491kB 59.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.18.5)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.32.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (50.3.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (2.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.0)\n",
      "\u001b[31mERROR: tensorflow-gpu 2.1.0 has requirement tensorboard<2.2.0,>=2.1.0, but you'll have tensorboard 1.14.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-gpu 2.1.0 has requirement tensorflow-estimator<2.2.0,>=2.1.0rc0, but you'll have tensorflow-estimator 1.14.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
      "  Found existing installation: tensorboard 2.1.1\n",
      "    Uninstalling tensorboard-2.1.1:\n",
      "      Successfully uninstalled tensorboard-2.1.1\n",
      "  Found existing installation: tensorflow-estimator 2.1.0\n",
      "    Uninstalling tensorflow-estimator-2.1.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.1.0\n",
      "  Found existing installation: tensorflow 2.3.0\n",
      "    Uninstalling tensorflow-2.3.0:\n",
      "      Successfully uninstalled tensorflow-2.3.0\n",
      "Successfully installed tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow==1.14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "yW2jDqCOX7Un",
    "outputId": "e0cae064-e7f4-4776-fed4-73d1e8516125"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "Cloning into 'fast-style-transfer-deeplearnjs'...\n",
      "remote: Enumerating objects: 1407, done.\u001b[K\n",
      "remote: Total 1407 (delta 0), reused 0 (delta 0), pack-reused 1407\u001b[K\n",
      "Receiving objects: 100% (1407/1407), 37.97 MiB | 1.56 MiB/s, done.\n",
      "Resolving deltas: 100% (135/135), done.\n",
      "/content/fast-style-transfer-deeplearnjs\n"
     ]
    }
   ],
   "source": [
    "%cd ../\n",
    "!git clone https://github.com/reiinakano/fast-style-transfer-deeplearnjs.git\n",
    "%cd fast-style-transfer-deeplearnjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "N6ky6qQhYJBz",
    "outputId": "60d8c1b8-4dfc-4d67-cea7-15a18695e140"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING:tensorflow:From scripts/dump_checkpoint_vars.py:48: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
      "\n",
      "WARNING:tensorflow:From scripts/dump_checkpoint_vars.py:51: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n",
      "Writing variable Variable_9/Adam_1...\n",
      "Writing variable Variable_8/Adam...\n",
      "Writing variable Variable_8...\n",
      "Writing variable Variable_7/Adam_1...\n",
      "Writing variable Variable_7/Adam...\n",
      "Writing variable Variable_7...\n",
      "Writing variable Variable_6/Adam...\n",
      "Writing variable Variable_6...\n",
      "Writing variable Variable_5/Adam...\n",
      "Writing variable Variable_47/Adam_1...\n",
      "Writing variable Variable_45/Adam_1...\n",
      "Writing variable Variable_45/Adam...\n",
      "Writing variable Variable_45...\n",
      "Writing variable Variable_43/Adam_1...\n",
      "Writing variable Variable_43/Adam...\n",
      "Writing variable Variable_43...\n",
      "Writing variable Variable_5/Adam_1...\n",
      "Writing variable Variable_42/Adam...\n",
      "Writing variable Variable_41/Adam...\n",
      "Writing variable Variable_41...\n",
      "Writing variable Variable_40...\n",
      "Writing variable Variable_39/Adam_1...\n",
      "Writing variable Variable_39...\n",
      "Writing variable Variable_38/Adam_1...\n",
      "Writing variable Variable_4/Adam_1...\n",
      "Writing variable Variable_38...\n",
      "Writing variable Variable_44...\n",
      "Writing variable Variable_20/Adam...\n",
      "Writing variable Variable_10/Adam...\n",
      "Writing variable Variable_37/Adam...\n",
      "Writing variable Variable_31/Adam...\n",
      "Writing variable Variable_19/Adam...\n",
      "Writing variable Variable_25...\n",
      "Writing variable Variable_9...\n",
      "Writing variable Variable_32/Adam...\n",
      "Writing variable Variable_34...\n",
      "Writing variable Variable_5...\n",
      "Writing variable Variable_47/Adam...\n",
      "Writing variable Variable_17/Adam_1...\n",
      "Writing variable Variable_32...\n",
      "Writing variable Variable_18/Adam...\n",
      "Writing variable Variable_17/Adam...\n",
      "Writing variable Variable_19/Adam_1...\n",
      "Writing variable Variable_11/Adam_1...\n",
      "Writing variable Variable_17...\n",
      "Writing variable Variable_18...\n",
      "Writing variable Variable_44/Adam_1...\n",
      "Writing variable Variable_36...\n",
      "Writing variable Variable_16...\n",
      "Writing variable Variable_2...\n",
      "Writing variable Variable_14/Adam_1...\n",
      "Writing variable beta2_power...\n",
      "Writing variable Variable_15...\n",
      "Writing variable Variable_30...\n",
      "Writing variable Variable_15/Adam_1...\n",
      "Writing variable Variable_46...\n",
      "Writing variable Variable_15/Adam...\n",
      "Writing variable Variable_24/Adam...\n",
      "Writing variable Variable_16/Adam...\n",
      "Writing variable Variable_11...\n",
      "Writing variable Variable_2/Adam_1...\n",
      "Writing variable Variable_41/Adam_1...\n",
      "Writing variable Variable_38/Adam...\n",
      "Writing variable Variable_23...\n",
      "Writing variable Variable_10/Adam_1...\n",
      "Writing variable Variable_24...\n",
      "Writing variable Variable_37/Adam_1...\n",
      "Writing variable Variable_47...\n",
      "Writing variable Variable_14...\n",
      "Writing variable Variable_20...\n",
      "Writing variable Variable_30/Adam...\n",
      "Writing variable Variable_1/Adam...\n",
      "Writing variable Variable_29/Adam_1...\n",
      "Writing variable Variable/Adam_1...\n",
      "Writing variable Variable_19...\n",
      "Writing variable Variable_21/Adam_1...\n",
      "Writing variable Variable_11/Adam...\n",
      "Writing variable Variable_29...\n",
      "Writing variable Variable_22...\n",
      "Writing variable Variable_16/Adam_1...\n",
      "Writing variable beta1_power...\n",
      "Writing variable Variable_40/Adam_1...\n",
      "Writing variable Variable_1...\n",
      "Writing variable Variable_44/Adam...\n",
      "Writing variable Variable_12...\n",
      "Writing variable Variable_36/Adam...\n",
      "Writing variable Variable/Adam...\n",
      "Writing variable Variable_25/Adam...\n",
      "Writing variable Variable_12/Adam_1...\n",
      "Writing variable Variable_23/Adam_1...\n",
      "Writing variable Variable_12/Adam...\n",
      "Writing variable Variable_21...\n",
      "Writing variable Variable_27...\n",
      "Writing variable Variable_4...\n",
      "Writing variable Variable_37...\n",
      "Writing variable Variable_10...\n",
      "Writing variable Variable_13...\n",
      "Writing variable Variable_28/Adam...\n",
      "Writing variable Variable_33/Adam_1...\n",
      "Writing variable Variable_13/Adam_1...\n",
      "Writing variable Variable_14/Adam...\n",
      "Writing variable Variable_3/Adam_1...\n",
      "Writing variable Variable_18/Adam_1...\n",
      "Writing variable Variable_2/Adam...\n",
      "Writing variable Variable_31/Adam_1...\n",
      "Writing variable Variable_9/Adam...\n",
      "Writing variable Variable_42/Adam_1...\n",
      "Writing variable Variable_22/Adam...\n",
      "Writing variable Variable_6/Adam_1...\n",
      "Writing variable Variable_22/Adam_1...\n",
      "Writing variable Variable_23/Adam...\n",
      "Writing variable Variable_28/Adam_1...\n",
      "Writing variable Variable_35/Adam_1...\n",
      "Writing variable Variable_20/Adam_1...\n",
      "Writing variable Variable_26/Adam...\n",
      "Writing variable Variable_40/Adam...\n",
      "Writing variable Variable_4/Adam...\n",
      "Writing variable Variable_30/Adam_1...\n",
      "Writing variable Variable_33/Adam...\n",
      "Writing variable Variable_26/Adam_1...\n",
      "Writing variable Variable_26...\n",
      "Writing variable Variable_27/Adam_1...\n",
      "Writing variable Variable_1/Adam_1...\n",
      "Writing variable Variable_29/Adam...\n",
      "Writing variable Variable_25/Adam_1...\n",
      "Writing variable Variable_28...\n",
      "Writing variable Variable_3...\n",
      "Writing variable Variable_42...\n",
      "Writing variable Variable_39/Adam...\n",
      "Writing variable Variable_3/Adam...\n",
      "Writing variable Variable_31...\n",
      "Writing variable Variable_8/Adam_1...\n",
      "Writing variable Variable_21/Adam...\n",
      "Writing variable Variable_32/Adam_1...\n",
      "Writing variable Variable_13/Adam...\n",
      "Writing variable Variable_27/Adam...\n",
      "Writing variable Variable_33...\n",
      "Writing variable Variable_34/Adam...\n",
      "Writing variable Variable_34/Adam_1...\n",
      "Writing variable Variable_46/Adam_1...\n",
      "Writing variable Variable_24/Adam_1...\n",
      "Writing variable Variable_35...\n",
      "Writing variable Variable_35/Adam...\n",
      "Writing variable Variable_46/Adam...\n",
      "Writing variable Variable...\n",
      "Writing variable Variable_36/Adam_1...\n",
      "Writing manifest to src/ckpts/pollock/manifest.json\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Change src/ckpts/picasso to src/ckpts/YOUR_OWN_FOLDER\n",
    "!python scripts/dump_checkpoint_vars.py --output_dir=src/ckpts/plaz --checkpoint_file=../fast-style-transfer/ckpt/fns.ckpt\n",
    "# Change src/ckpts/picasso to src/ckpts/YOUR_OWN_FOLDER\n",
    "!python scripts/remove_optimizer_variables.py --output_dir=src/ckpts/plaz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "id": "YCt42jBqY_rA",
    "outputId": "1540202d-537c-49ab-8675-b3a0ac321ae4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/ (stored 0%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_47 (stored 0%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_25 (stored 0%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_43 (stored 0%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_13 (stored 0%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable (deflated 7%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_28 (deflated 2%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_40 (stored 0%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_37 (stored 0%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_26 (deflated 4%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_23 (deflated 4%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_41 (deflated 1%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_11 (deflated 4%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_7 (stored 0%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_36 (deflated 7%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_12 (deflated 7%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_14 (deflated 2%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_17 (deflated 5%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_5 (stored 0%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_32 (deflated 5%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_42 (deflated 7%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_10 (deflated 2%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_29 (deflated 5%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_20 (deflated 3%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_44 (stored 0%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_34 (deflated 2%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_1 (stored 0%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_33 (deflated 7%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_9 (deflated 7%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_45 (deflated 7%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_22 (stored 0%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_6 (deflated 7%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_18 (deflated 7%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_16 (stored 0%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_46 (stored 0%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_15 (deflated 7%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_4 (stored 0%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_21 (deflated 7%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_19 (stored 0%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_38 (deflated 4%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_24 (deflated 7%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/manifest.json (deflated 91%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_8 (deflated 1%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_35 (deflated 6%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_27 (deflated 7%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_2 (stored 0%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_30 (deflated 7%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_3 (deflated 7%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_31 (stored 0%)\n",
      "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_39 (deflated 7%)\n"
     ]
    }
   ],
   "source": [
    "# Change /piccasso.zip to /YOUR_FOLDER_NAME.zip, same as src/ckpts/picasso to /YOUR_FOLDER_NAME\n",
    "!zip -r /content/fast-style-transfer-deeplearnjs/src/ckpts/picasso.zip /content/fast-style-transfer-deeplearnjs/src/ckpts/picasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n8_X2DJIMiJW"
   },
   "source": [
    "# 5. Run it with ml5js\n",
    "Now, you should be able to see a 'pollock' .zip file at \"fast-style-transfer-deeplearnjs/src/ckpts/pollock.zip\". (Sometimes, you need to refresh the Files panel, right click to refresh)\n",
    "\n",
    "Download the 'pollock' folder and put it into your p5 sketch(https://github.com/yining1023/machine-learning-for-the-web/tree/master/week5-styleTransfer/styleTransfer-ml5/StyleTransfer_Video) under models/.\n",
    "\n",
    "Change the model path in your p5 sketch: style = ml5.styleTransfer('models/pollock', video, modelLoaded);"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
